{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2324682e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, sys, time, random\n",
    "import numpy as np\n",
    "import torch\n",
    "from  easydict import EasyDict\n",
    "from math import floor\n",
    "from easydict import EasyDict\n",
    "\n",
    "from steves_utils.vanilla_train_eval_test_jig import  Vanilla_Train_Eval_Test_Jig\n",
    "\n",
    "from steves_utils.torch_utils import get_dataset_metrics, independent_accuracy_assesment\n",
    "from steves_models.configurable_vanilla import Configurable_Vanilla\n",
    "from steves_utils.torch_sequential_builder import build_sequential\n",
    "from steves_utils.lazy_map import Lazy_Map\n",
    "from steves_utils.sequence_aggregator import Sequence_Aggregator\n",
    "\n",
    "from steves_utils.stratified_dataset.traditional_accessor import Traditional_Accessor_Factory\n",
    "\n",
    "from steves_utils.cnn_do_report import (\n",
    "    get_loss_curve,\n",
    "    get_results_table,\n",
    "    get_parameters_table,\n",
    "    get_domain_accuracies,\n",
    ")\n",
    "\n",
    "from steves_utils.torch_utils import (\n",
    "    confusion_by_domain_over_dataloader,\n",
    "    independent_accuracy_assesment\n",
    ")\n",
    "\n",
    "from steves_utils.utils_v2 import (\n",
    "    per_domain_accuracy_from_confusion,\n",
    "    get_datasets_base_path\n",
    ")\n",
    "\n",
    "# from steves_utils.ptn_do_report import TBD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b29e3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "required_parameters = {\n",
    "    \"experiment_name\",\n",
    "    \"lr\",\n",
    "    \"device\",\n",
    "    \"dataset_seed\",\n",
    "    \"seed\",\n",
    "    \"labels\",\n",
    "    \"domains_target\",\n",
    "    \"domains_source\",\n",
    "    \"num_examples_per_domain_per_label\",\n",
    "    \"batch_size\",\n",
    "    \"n_epoch\",\n",
    "    \"patience\",\n",
    "    \"criteria_for_best\",\n",
    "    \"normalize_source\",\n",
    "    \"normalize_target\",\n",
    "    \"x_net\",\n",
    "    \"NUM_LOGS_PER_EPOCH\",\n",
    "    \"BEST_MODEL_PATH\",\n",
    "    \"pickle_name\",\n",
    "    \"torch_default_dtype\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670b5fb8",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "from steves_utils.CORES.utils import (\n",
    "    ALL_NODES,\n",
    "    ALL_NODES_MINIMUM_1000_EXAMPLES,\n",
    "    ALL_DAYS,\n",
    "    node_name_to_id\n",
    ")\n",
    "\n",
    "standalone_parameters = {}\n",
    "standalone_parameters[\"experiment_name\"] = \"MANUAL CORES CNN\"\n",
    "standalone_parameters[\"lr\"] = 0.001\n",
    "standalone_parameters[\"device\"] = \"cpu\"\n",
    "\n",
    "standalone_parameters[\"dataset_seed\"] = 1337\n",
    "standalone_parameters[\"seed\"] = 1337\n",
    "standalone_parameters[\"labels\"] = ALL_NODES_MINIMUM_1000_EXAMPLES\n",
    "\n",
    "standalone_parameters[\"domains_target\"] = [1]\n",
    "standalone_parameters[\"domains_source\"] = [2,3,4,5]\n",
    "\n",
    "standalone_parameters[\"num_examples_per_domain_per_label\"]=100\n",
    "\n",
    "standalone_parameters[\"pickle_name\"] = \"cores.stratified_ds.2022A.pkl\"\n",
    "\n",
    "standalone_parameters[\"torch_default_dtype\"] = \"torch.float32\" \n",
    "\n",
    "standalone_parameters[\"batch_size\"]=128\n",
    "\n",
    "standalone_parameters[\"n_epoch\"] = 3\n",
    "\n",
    "standalone_parameters[\"patience\"] = 10\n",
    "\n",
    "standalone_parameters[\"criteria_for_best\"] = \"target\"\n",
    "standalone_parameters[\"normalize_source\"] = False\n",
    "standalone_parameters[\"normalize_target\"] = False\n",
    "\n",
    "standalone_parameters[\"x_net\"] =     [\n",
    "    {\"class\": \"nnReshape\", \"kargs\": {\"shape\":[-1, 1, 2, 256]}},\n",
    "    {\"class\": \"Conv2d\", \"kargs\": { \"in_channels\":1, \"out_channels\":256, \"kernel_size\":(1,7), \"bias\":False, \"padding\":(0,3), },},\n",
    "    {\"class\": \"ReLU\", \"kargs\": {\"inplace\": True}},\n",
    "    {\"class\": \"BatchNorm2d\", \"kargs\": {\"num_features\":256}},\n",
    "\n",
    "    {\"class\": \"Conv2d\", \"kargs\": { \"in_channels\":256, \"out_channels\":80, \"kernel_size\":(2,7), \"bias\":True, \"padding\":(0,3), },},\n",
    "    {\"class\": \"ReLU\", \"kargs\": {\"inplace\": True}},\n",
    "    {\"class\": \"BatchNorm2d\", \"kargs\": {\"num_features\":80}},\n",
    "    {\"class\": \"Flatten\", \"kargs\": {}},\n",
    "\n",
    "    {\"class\": \"Linear\", \"kargs\": {\"in_features\": 80*256, \"out_features\": 256}}, # 80 units per IQ pair\n",
    "    {\"class\": \"ReLU\", \"kargs\": {\"inplace\": True}},\n",
    "    {\"class\": \"BatchNorm1d\", \"kargs\": {\"num_features\":256}},\n",
    "\n",
    "    {\"class\": \"Linear\", \"kargs\": {\"in_features\": 256, \"out_features\": len(standalone_parameters[\"labels\"])}},\n",
    "]\n",
    "\n",
    "standalone_parameters[\"NUM_LOGS_PER_EPOCH\"] = 10\n",
    "standalone_parameters[\"BEST_MODEL_PATH\"] = \"./best_model.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759b56ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set this to True if you want to run this template directly\n",
    "STANDALONE = True\n",
    "if STANDALONE:\n",
    "    print(\"parameters not injected, running with standalone_parameters\")\n",
    "    parameters = standalone_parameters\n",
    "\n",
    "if not 'parameters' in locals() and not 'parameters' in globals():\n",
    "    raise Exception(\"Parameter injection failed\")\n",
    "\n",
    "#Use an easy dict for all the parameters\n",
    "p = EasyDict(parameters)\n",
    "\n",
    "supplied_keys = set(p.keys())\n",
    "\n",
    "if  supplied_keys != required_parameters:\n",
    "    print(\"Parameters are incorrect\")\n",
    "    if len(supplied_keys - required_parameters)>0: print(\"Shouldn't have:\", str(supplied_keys - required_parameters))\n",
    "    if len(required_parameters - supplied_keys)>0: print(\"Need to have:\", str(required_parameters - supplied_keys))\n",
    "    raise RuntimeError(\"Parameters are incorrect\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c66a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################\n",
    "# Set the RNGs and make it all deterministic\n",
    "###################################\n",
    "np.random.seed(p.seed)\n",
    "random.seed(p.seed)\n",
    "torch.manual_seed(p.seed)\n",
    "\n",
    "torch.use_deterministic_algorithms(True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a65876",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_dtype(eval(p.torch_default_dtype))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a32f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################\n",
    "# Build the network(s)\n",
    "# Note: It's critical to do this AFTER setting the RNG\n",
    "###################################\n",
    "x_net = build_sequential(p.x_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a276cd83",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time_secs = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de702e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrap_in_dataloader(p, ds):\n",
    "    return torch.utils.data.DataLoader(\n",
    "        ds,\n",
    "        batch_size=p.batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=1,\n",
    "        persistent_workers=True,\n",
    "        prefetch_factor=50,\n",
    "        pin_memory=True\n",
    "    )\n",
    "\n",
    "taf_source = Traditional_Accessor_Factory(\n",
    "    labels=p.labels,\n",
    "    domains=p.domains_source,\n",
    "    num_examples_per_domain_per_label=p.num_examples_per_domain_per_label,\n",
    "    pickle_path=os.path.join(get_datasets_base_path(), p.pickle_name),\n",
    "    seed=p.dataset_seed\n",
    ")\n",
    "train_original_source, val_original_source, test_original_source = \\\n",
    "    taf_source.get_train(), taf_source.get_val(), taf_source.get_test()\n",
    "\n",
    "\n",
    "taf_target = Traditional_Accessor_Factory(\n",
    "    labels=p.labels,\n",
    "    domains=p.domains_target,\n",
    "    num_examples_per_domain_per_label=p.num_examples_per_domain_per_label,\n",
    "    pickle_path=os.path.join(get_datasets_base_path(), p.pickle_name),\n",
    "    seed=p.dataset_seed\n",
    ")\n",
    "train_original_target, val_original_target, test_original_target = \\\n",
    "    taf_target.get_train(), taf_target.get_val(), taf_target.get_test()\n",
    "\n",
    "\n",
    "# For CNN We only use X and Y. And we only train on the source.\n",
    "# Properly form the data using a transform lambda and Lazy_Map. Finally wrap them in a dataloader\n",
    "\n",
    "transform_lambda = lambda ex: ex[:2] # Strip the tuple to just (x,y)\n",
    "\n",
    "\n",
    "train_processed_source = wrap_in_dataloader(\n",
    "    p,\n",
    "    Lazy_Map(train_original_source, transform_lambda)\n",
    ")\n",
    "val_processed_source = wrap_in_dataloader(\n",
    "    p,\n",
    "    Lazy_Map(val_original_source, transform_lambda)\n",
    ")\n",
    "test_processed_source = wrap_in_dataloader(\n",
    "    p,\n",
    "    Lazy_Map(test_original_source, transform_lambda)\n",
    ")\n",
    "\n",
    "train_processed_target = wrap_in_dataloader(\n",
    "    p,\n",
    "    Lazy_Map(train_original_source, transform_lambda)\n",
    ")\n",
    "val_processed_target = wrap_in_dataloader(\n",
    "    p,\n",
    "    Lazy_Map(val_original_source, transform_lambda)\n",
    ")\n",
    "test_processed_target  = wrap_in_dataloader(\n",
    "    p,\n",
    "    Lazy_Map(test_original_source, transform_lambda)\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "datasets = EasyDict({\n",
    "    \"source\": {\n",
    "        \"original\": {\"train\":train_original_source, \"val\":val_original_source, \"test\":test_original_source},\n",
    "        \"processed\": {\"train\":train_processed_source, \"val\":val_processed_source, \"test\":test_processed_source}\n",
    "    },\n",
    "    \"target\": {\n",
    "        \"original\": {\"train\":train_original_target, \"val\":val_original_target, \"test\":test_original_target},\n",
    "        \"processed\": {\"train\":train_processed_target, \"val\":val_processed_target, \"test\":test_processed_target}\n",
    "    },\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11b26bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ep = next(iter(test_processed_target))\n",
    "ep[0].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19425fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Configurable_Vanilla(\n",
    "    x_net=x_net,\n",
    "    label_loss_object=torch.nn.NLLLoss(),\n",
    "    learning_rate=p.lr\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6d4f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "jig = Vanilla_Train_Eval_Test_Jig(\n",
    "    model=model,\n",
    "    path_to_best_model=p.BEST_MODEL_PATH,\n",
    "    device=p.device,\n",
    "    label_loss_object=torch.nn.NLLLoss(),\n",
    ")\n",
    "\n",
    "jig.train(\n",
    "    train_iterable=datasets.source.processed.train,\n",
    "    source_val_iterable=datasets.source.processed.val,\n",
    "    target_val_iterable=datasets.target.processed.val,\n",
    "    patience=p.patience,\n",
    "    num_epochs=p.n_epoch,\n",
    "    num_logs_per_epoch=p.NUM_LOGS_PER_EPOCH,\n",
    "    criteria_for_best=p.criteria_for_best\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc2ac17",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_experiment_time_secs = time.time() - start_time_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae88f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_test_label_accuracy, source_test_label_loss = jig.test(datasets.source.processed.test)\n",
    "target_test_label_accuracy, target_test_label_loss = jig.test(datasets.target.processed.test)\n",
    "\n",
    "source_val_label_accuracy, source_val_label_loss = jig.test(datasets.source.processed.val)\n",
    "target_val_label_accuracy, target_val_label_loss = jig.test(datasets.target.processed.val)\n",
    "\n",
    "history = jig.get_history()\n",
    "\n",
    "total_epochs_trained = len(history[\"epoch_indices\"])\n",
    "\n",
    "val_dl = wrap_in_dataloader(p, Sequence_Aggregator((datasets.source.original.val, datasets.target.original.val)))\n",
    "\n",
    "confusion = confusion_by_domain_over_dataloader(model, p.device, val_dl, forward_uses_domain=False)\n",
    "per_domain_accuracy = per_domain_accuracy_from_confusion(confusion)\n",
    "\n",
    "# Add a key to per_domain_accuracy for if it was a source domain\n",
    "for domain, accuracy in per_domain_accuracy.items():\n",
    "    per_domain_accuracy[domain] = {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"source?\": domain in p.domains_source\n",
    "    }\n",
    "\n",
    "# Do an independent accuracy assesment JUST TO BE SURE!\n",
    "# _source_test_label_accuracy = independent_accuracy_assesment(model, datasets.source.processed.test, p.device)\n",
    "# _target_test_label_accuracy = independent_accuracy_assesment(model, datasets.target.processed.test, p.device)\n",
    "# _source_val_label_accuracy = independent_accuracy_assesment(model, datasets.source.processed.val, p.device)\n",
    "# _target_val_label_accuracy = independent_accuracy_assesment(model, datasets.target.processed.val, p.device)\n",
    "\n",
    "# assert(_source_test_label_accuracy == source_test_label_accuracy)\n",
    "# assert(_target_test_label_accuracy == target_test_label_accuracy)\n",
    "# assert(_source_val_label_accuracy == source_val_label_accuracy)\n",
    "# assert(_target_val_label_accuracy == target_val_label_accuracy)\n",
    "\n",
    "###################################\n",
    "# Write out the results\n",
    "###################################\n",
    "\n",
    "experiment = {\n",
    "    \"experiment_name\": p.experiment_name,\n",
    "    \"parameters\": p,\n",
    "    \"results\": {\n",
    "        \"source_test_label_accuracy\": source_test_label_accuracy,\n",
    "        \"source_test_label_loss\": source_test_label_loss,\n",
    "        \"target_test_label_accuracy\": target_test_label_accuracy,\n",
    "        \"target_test_label_loss\": target_test_label_loss,\n",
    "        \"source_val_label_accuracy\": source_val_label_accuracy,\n",
    "        \"source_val_label_loss\": source_val_label_loss,\n",
    "        \"target_val_label_accuracy\": target_val_label_accuracy,\n",
    "        \"target_val_label_loss\": target_val_label_loss,\n",
    "        \"total_epochs_trained\": total_epochs_trained,\n",
    "        \"total_experiment_time_secs\": total_experiment_time_secs,\n",
    "        \"confusion\": confusion,\n",
    "        \"per_domain_accuracy\": per_domain_accuracy,\n",
    "    },\n",
    "    \"history\": history,\n",
    "    \"dataset_metrics\": get_dataset_metrics(datasets, \"cnn\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c318cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_loss_curve(experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59376601",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_results_table(experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80c5c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_domain_accuracies(experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086fdd10",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Source Test Label Accuracy:\", experiment[\"results\"][\"source_test_label_accuracy\"], \"Target Test Label Accuracy:\", experiment[\"results\"][\"target_test_label_accuracy\"])\n",
    "print(\"Source Val Label Accuracy:\", experiment[\"results\"][\"source_val_label_accuracy\"], \"Target Val Label Accuracy:\", experiment[\"results\"][\"target_val_label_accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f450536",
   "metadata": {
    "tags": [
     "experiment_json"
    ]
   },
   "outputs": [],
   "source": [
    "json.dumps(experiment)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
