{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2324682e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, sys, time, random\n",
    "import numpy as np\n",
    "import torch\n",
    "from  easydict import EasyDict\n",
    "from math import floor\n",
    "from easydict import EasyDict\n",
    "\n",
    "from steves_utils.vanilla_train_eval_test_jig import  Vanilla_Train_Eval_Test_Jig\n",
    "\n",
    "from steves_utils.torch_utils import get_dataset_metrics, independent_accuracy_assesment\n",
    "from steves_models.configurable_vanilla import Configurable_Vanilla\n",
    "from steves_utils.torch_sequential_builder import build_sequential\n",
    "from steves_utils.lazy_map import Lazy_Map\n",
    "from steves_utils.sequence_aggregator import Sequence_Aggregator\n",
    "\n",
    "from steves_utils.stratified_dataset.traditional_accessor import Traditional_Accessor_Factory\n",
    "\n",
    "\n",
    "\n",
    "from steves_utils.torch_utils import (\n",
    "    confusion_by_domain_over_dataloader,\n",
    "    independent_accuracy_assesment\n",
    ")\n",
    "\n",
    "from steves_utils.utils_v2 import (\n",
    "    per_domain_accuracy_from_confusion,\n",
    "    get_datasets_base_path\n",
    ")\n",
    "\n",
    "# from steves_utils.ptn_do_report import TBD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b29e3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "required_parameters = {\n",
    "    \"experiment_name\",\n",
    "    \"lr\",\n",
    "    \"device\",\n",
    "    \"dataset_seed\",\n",
    "    \"seed\",\n",
    "    \"labels\",\n",
    "    \"domains_target\",\n",
    "    \"domains_source\",\n",
    "    \"num_examples_per_domain_per_label\",\n",
    "    \"batch_size\",\n",
    "    \"n_epoch\",\n",
    "    \"patience\",\n",
    "    \"criteria_for_best\",\n",
    "    \"normalize_source\",\n",
    "    \"normalize_target\",\n",
    "    \"x_net\",\n",
    "    \"NUM_LOGS_PER_EPOCH\",\n",
    "    \"BEST_MODEL_PATH\",\n",
    "    \"pickle_name\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "670b5fb8",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "from steves_utils.CORES.utils import (\n",
    "    ALL_NODES,\n",
    "    ALL_NODES_MINIMUM_1000_EXAMPLES,\n",
    "    ALL_DAYS,\n",
    "    node_name_to_id\n",
    ")\n",
    "\n",
    "standalone_parameters = {}\n",
    "standalone_parameters[\"experiment_name\"] = \"MANUAL CORES CNN\"\n",
    "standalone_parameters[\"lr\"] = 0.001\n",
    "standalone_parameters[\"device\"] = \"cpu\"\n",
    "\n",
    "standalone_parameters[\"dataset_seed\"] = 1337\n",
    "standalone_parameters[\"seed\"] = 1337\n",
    "standalone_parameters[\"labels\"] = ALL_NODES_MINIMUM_1000_EXAMPLES\n",
    "\n",
    "standalone_parameters[\"domains_target\"] = [1]\n",
    "standalone_parameters[\"domains_source\"] = [2,3,4,5]\n",
    "\n",
    "standalone_parameters[\"num_examples_per_domain_per_label\"]=100\n",
    "\n",
    "standalone_parameters[\"pickle_name\"] = \"cores.stratified_ds.2022A.pkl\"\n",
    "\n",
    "standalone_parameters[\"batch_size\"]=128\n",
    "\n",
    "standalone_parameters[\"n_epoch\"] = 3\n",
    "\n",
    "standalone_parameters[\"patience\"] = 10\n",
    "\n",
    "standalone_parameters[\"criteria_for_best\"] = \"target\"\n",
    "standalone_parameters[\"normalize_source\"] = False\n",
    "standalone_parameters[\"normalize_target\"] = False\n",
    "\n",
    "standalone_parameters[\"x_net\"] =     [\n",
    "    {\"class\": \"nnReshape\", \"kargs\": {\"shape\":[-1, 1, 2, 256]}},\n",
    "    {\"class\": \"Conv2d\", \"kargs\": { \"in_channels\":1, \"out_channels\":256, \"kernel_size\":(1,7), \"bias\":False, \"padding\":(0,3), },},\n",
    "    {\"class\": \"ReLU\", \"kargs\": {\"inplace\": True}},\n",
    "    {\"class\": \"BatchNorm2d\", \"kargs\": {\"num_features\":256}},\n",
    "\n",
    "    {\"class\": \"Conv2d\", \"kargs\": { \"in_channels\":256, \"out_channels\":80, \"kernel_size\":(2,7), \"bias\":True, \"padding\":(0,3), },},\n",
    "    {\"class\": \"ReLU\", \"kargs\": {\"inplace\": True}},\n",
    "    {\"class\": \"BatchNorm2d\", \"kargs\": {\"num_features\":80}},\n",
    "    {\"class\": \"Flatten\", \"kargs\": {}},\n",
    "\n",
    "    {\"class\": \"Linear\", \"kargs\": {\"in_features\": 80*256, \"out_features\": 256}}, # 80 units per IQ pair\n",
    "    {\"class\": \"ReLU\", \"kargs\": {\"inplace\": True}},\n",
    "    {\"class\": \"BatchNorm1d\", \"kargs\": {\"num_features\":256}},\n",
    "\n",
    "    {\"class\": \"Linear\", \"kargs\": {\"in_features\": 256, \"out_features\": len(standalone_parameters[\"labels\"])}},\n",
    "]\n",
    "\n",
    "standalone_parameters[\"NUM_LOGS_PER_EPOCH\"] = 10\n",
    "standalone_parameters[\"BEST_MODEL_PATH\"] = \"./best_model.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "759b56ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters not injected, running with standalone_parameters\n"
     ]
    }
   ],
   "source": [
    "# Set this to True if you want to run this template directly\n",
    "STANDALONE = True\n",
    "if STANDALONE:\n",
    "    print(\"parameters not injected, running with standalone_parameters\")\n",
    "    parameters = standalone_parameters\n",
    "\n",
    "if not 'parameters' in locals() and not 'parameters' in globals():\n",
    "    raise Exception(\"Parameter injection failed\")\n",
    "\n",
    "#Use an easy dict for all the parameters\n",
    "p = EasyDict(parameters)\n",
    "\n",
    "supplied_keys = set(p.keys())\n",
    "\n",
    "if  supplied_keys != required_parameters:\n",
    "    print(\"Parameters are incorrect\")\n",
    "    if len(supplied_keys - required_parameters)>0: print(\"Shouldn't have:\", str(supplied_keys - required_parameters))\n",
    "    if len(required_parameters - supplied_keys)>0: print(\"Need to have:\", str(required_parameters - supplied_keys))\n",
    "    raise RuntimeError(\"Parameters are incorrect\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5c66a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################\n",
    "# Set the RNGs and make it all deterministic\n",
    "###################################\n",
    "np.random.seed(p.seed)\n",
    "random.seed(p.seed)\n",
    "torch.manual_seed(p.seed)\n",
    "\n",
    "torch.use_deterministic_algorithms(True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1a32f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################\n",
    "# Build the network(s)\n",
    "# Note: It's critical to do this AFTER setting the RNG\n",
    "###################################\n",
    "x_net = build_sequential(p.x_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a276cd83",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time_secs = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de702e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrap_in_dataloader(p, ds):\n",
    "    return torch.utils.data.DataLoader(\n",
    "        ds,\n",
    "        batch_size=p.batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=1,\n",
    "        persistent_workers=True,\n",
    "        prefetch_factor=50,\n",
    "        pin_memory=True\n",
    "    )\n",
    "\n",
    "taf_source = Traditional_Accessor_Factory(\n",
    "    labels=p.labels,\n",
    "    domains=p.domains_source,\n",
    "    num_examples_per_domain_per_label=p.num_examples_per_domain_per_label,\n",
    "    pickle_path=os.path.join(get_datasets_base_path(), p.pickle_name),\n",
    "    seed=p.dataset_seed\n",
    ")\n",
    "train_original_source, val_original_source, test_original_source = \\\n",
    "    taf_source.get_train(), taf_source.get_val(), taf_source.get_test()\n",
    "\n",
    "\n",
    "taf_target = Traditional_Accessor_Factory(\n",
    "    labels=p.labels,\n",
    "    domains=p.domains_target,\n",
    "    num_examples_per_domain_per_label=p.num_examples_per_domain_per_label,\n",
    "    pickle_path=os.path.join(get_datasets_base_path(), p.pickle_name),\n",
    "    seed=p.dataset_seed\n",
    ")\n",
    "train_original_target, val_original_target, test_original_target = \\\n",
    "    taf_target.get_train(), taf_target.get_val(), taf_target.get_test()\n",
    "\n",
    "\n",
    "# For CNN We only use X and Y. And we only train on the source.\n",
    "# Properly form the data using a transform lambda and Lazy_Map. Finally wrap them in a dataloader\n",
    "\n",
    "transform_lambda = lambda ex: ex[:2] # Strip the tuple to just (x,y)\n",
    "\n",
    "\n",
    "train_processed_source = wrap_in_dataloader(\n",
    "    p,\n",
    "    Lazy_Map(train_original_source, transform_lambda)\n",
    ")\n",
    "val_processed_source = wrap_in_dataloader(\n",
    "    p,\n",
    "    Lazy_Map(val_original_source, transform_lambda)\n",
    ")\n",
    "test_processed_source = wrap_in_dataloader(\n",
    "    p,\n",
    "    Lazy_Map(test_original_source, transform_lambda)\n",
    ")\n",
    "\n",
    "train_processed_target = wrap_in_dataloader(\n",
    "    p,\n",
    "    Lazy_Map(train_original_source, transform_lambda)\n",
    ")\n",
    "val_processed_target = wrap_in_dataloader(\n",
    "    p,\n",
    "    Lazy_Map(val_original_source, transform_lambda)\n",
    ")\n",
    "test_processed_target  = wrap_in_dataloader(\n",
    "    p,\n",
    "    Lazy_Map(test_original_source, transform_lambda)\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "datasets = EasyDict({\n",
    "    \"source\": {\n",
    "        \"original\": {\"train\":train_original_source, \"val\":val_original_source, \"test\":test_original_source},\n",
    "        \"processed\": {\"train\":train_processed_source, \"val\":val_processed_source, \"test\":test_processed_source}\n",
    "    },\n",
    "    \"target\": {\n",
    "        \"original\": {\"train\":train_original_target, \"val\":val_original_target, \"test\":test_original_target},\n",
    "        \"processed\": {\"train\":train_processed_target, \"val\":val_processed_target, \"test\":test_processed_target}\n",
    "    },\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19425fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Configurable_Vanilla(\n",
    "    x_net=x_net,\n",
    "    label_loss_object=torch.nn.NLLLoss(),\n",
    "    learning_rate=p.lr\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f6d4f2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, [batch: 1 / 40], examples_per_second: 122.9732, train_label_loss: 2.4735, \n",
      "epoch: 1, [batch: 4 / 40], examples_per_second: 153.6011, train_label_loss: 2.0009, \n",
      "epoch: 1, [batch: 8 / 40], examples_per_second: 168.6940, train_label_loss: 1.5682, \n",
      "epoch: 1, [batch: 12 / 40], examples_per_second: 165.4495, train_label_loss: 1.3763, \n",
      "epoch: 1, [batch: 16 / 40], examples_per_second: 164.8677, train_label_loss: 1.0882, \n",
      "epoch: 1, [batch: 20 / 40], examples_per_second: 167.6946, train_label_loss: 0.8548, \n",
      "epoch: 1, [batch: 24 / 40], examples_per_second: 167.5614, train_label_loss: 0.8543, \n",
      "epoch: 1, [batch: 28 / 40], examples_per_second: 159.6703, train_label_loss: 0.6175, \n",
      "epoch: 1, [batch: 32 / 40], examples_per_second: 167.7544, train_label_loss: 0.4839, \n",
      "epoch: 1, [batch: 36 / 40], examples_per_second: 168.0252, train_label_loss: 0.5457, \n",
      "=============================================================\n",
      "epoch: 1, source_val_acc_label: 0.0556, source_val_label_loss: 8.1941, target_val_acc_label: 0.0556, target_val_label_loss: 8.1555, \n",
      "=============================================================\n",
      "New best\n",
      "epoch: 2, [batch: 1 / 40], examples_per_second: 34.3068, train_label_loss: 0.2843, \n",
      "epoch: 2, [batch: 4 / 40], examples_per_second: 157.6743, train_label_loss: 0.2719, \n",
      "epoch: 2, [batch: 8 / 40], examples_per_second: 163.0131, train_label_loss: 0.2407, \n",
      "epoch: 2, [batch: 12 / 40], examples_per_second: 147.3681, train_label_loss: 0.1853, \n",
      "epoch: 2, [batch: 16 / 40], examples_per_second: 155.7236, train_label_loss: 0.1701, \n",
      "epoch: 2, [batch: 20 / 40], examples_per_second: 161.9967, train_label_loss: 0.1274, \n",
      "epoch: 2, [batch: 24 / 40], examples_per_second: 159.9177, train_label_loss: 0.1074, \n",
      "epoch: 2, [batch: 28 / 40], examples_per_second: 132.7403, train_label_loss: 0.1040, \n",
      "epoch: 2, [batch: 32 / 40], examples_per_second: 155.0603, train_label_loss: 0.0930, \n",
      "epoch: 2, [batch: 36 / 40], examples_per_second: 151.4816, train_label_loss: 0.1178, \n",
      "=============================================================\n",
      "epoch: 2, source_val_acc_label: 0.3981, source_val_label_loss: 2.2271, target_val_acc_label: 0.3981, target_val_label_loss: 2.2352, \n",
      "=============================================================\n",
      "New best\n",
      "epoch: 3, [batch: 1 / 40], examples_per_second: 32.7455, train_label_loss: 0.0694, \n",
      "epoch: 3, [batch: 4 / 40], examples_per_second: 150.3771, train_label_loss: 0.0580, \n",
      "epoch: 3, [batch: 8 / 40], examples_per_second: 158.7394, train_label_loss: 0.0434, \n",
      "epoch: 3, [batch: 12 / 40], examples_per_second: 130.4107, train_label_loss: 0.0303, \n",
      "epoch: 3, [batch: 16 / 40], examples_per_second: 139.8751, train_label_loss: 0.0348, \n",
      "epoch: 3, [batch: 20 / 40], examples_per_second: 162.2268, train_label_loss: 0.0673, \n",
      "epoch: 3, [batch: 24 / 40], examples_per_second: 144.1662, train_label_loss: 0.0361, \n",
      "epoch: 3, [batch: 28 / 40], examples_per_second: 150.0783, train_label_loss: 0.0713, \n",
      "epoch: 3, [batch: 32 / 40], examples_per_second: 164.1449, train_label_loss: 0.0285, \n",
      "epoch: 3, [batch: 36 / 40], examples_per_second: 165.9366, train_label_loss: 0.0355, \n",
      "=============================================================\n",
      "epoch: 3, source_val_acc_label: 0.9787, source_val_label_loss: 0.0901, target_val_acc_label: 0.9787, target_val_label_loss: 0.0947, \n",
      "=============================================================\n",
      "New best\n"
     ]
    }
   ],
   "source": [
    "jig = Vanilla_Train_Eval_Test_Jig(\n",
    "    model=model,\n",
    "    path_to_best_model=p.BEST_MODEL_PATH,\n",
    "    device=p.device,\n",
    "    label_loss_object=torch.nn.NLLLoss(),\n",
    ")\n",
    "\n",
    "jig.train(\n",
    "    train_iterable=datasets.source.processed.train,\n",
    "    source_val_iterable=datasets.source.processed.val,\n",
    "    target_val_iterable=datasets.target.processed.val,\n",
    "    patience=p.patience,\n",
    "    num_epochs=p.n_epoch,\n",
    "    num_logs_per_epoch=p.NUM_LOGS_PER_EPOCH,\n",
    "    criteria_for_best=p.criteria_for_best\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4bc2ac17",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_experiment_time_secs = time.time() - start_time_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cae88f23",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_41661/1848401989.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     54\u001b[0m     },\n\u001b[1;32m     55\u001b[0m     \u001b[0;34m\"history\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0;34m\"dataset_metrics\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mget_dataset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"cnn\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m }\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ds' is not defined"
     ]
    }
   ],
   "source": [
    "source_test_label_accuracy, source_test_label_loss = jig.test(datasets.source.processed.test)\n",
    "target_test_label_accuracy, target_test_label_loss = jig.test(datasets.target.processed.test)\n",
    "\n",
    "source_val_label_accuracy, source_val_label_loss = jig.test(datasets.source.processed.val)\n",
    "target_val_label_accuracy, target_val_label_loss = jig.test(datasets.target.processed.val)\n",
    "\n",
    "history = jig.get_history()\n",
    "\n",
    "total_epochs_trained = len(history[\"epoch_indices\"])\n",
    "\n",
    "val_dl = wrap_in_dataloader(p, Sequence_Aggregator((datasets.source.original.val, datasets.target.original.val)))\n",
    "\n",
    "confusion = confusion_by_domain_over_dataloader(model, p.device, val_dl, forward_uses_domain=False)\n",
    "per_domain_accuracy = per_domain_accuracy_from_confusion(confusion)\n",
    "\n",
    "# Add a key to per_domain_accuracy for if it was a source domain\n",
    "for domain, accuracy in per_domain_accuracy.items():\n",
    "    per_domain_accuracy[domain] = {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"source?\": domain in p.domains_source\n",
    "    }\n",
    "\n",
    "# Do an independent accuracy assesment JUST TO BE SURE!\n",
    "_source_test_label_accuracy = independent_accuracy_assesment(model, datasets.source.processed.test, p.device)\n",
    "_target_test_label_accuracy = independent_accuracy_assesment(model, datasets.target.processed.test, p.device)\n",
    "_source_val_label_accuracy = independent_accuracy_assesment(model, datasets.source.processed.val, p.device)\n",
    "_target_val_label_accuracy = independent_accuracy_assesment(model, datasets.target.processed.val, p.device)\n",
    "\n",
    "assert(_source_test_label_accuracy == source_test_label_accuracy)\n",
    "assert(_target_test_label_accuracy == target_test_label_accuracy)\n",
    "assert(_source_val_label_accuracy == source_val_label_accuracy)\n",
    "assert(_target_val_label_accuracy == target_val_label_accuracy)\n",
    "\n",
    "###################################\n",
    "# Write out the results\n",
    "###################################\n",
    "\n",
    "experiment = {\n",
    "    \"experiment_name\": p.experiment_name,\n",
    "    \"parameters\": p,\n",
    "    \"results\": {\n",
    "        \"source_test_label_accuracy\": source_test_label_accuracy,\n",
    "        \"source_test_label_loss\": source_test_label_loss,\n",
    "        \"target_test_label_accuracy\": target_test_label_accuracy,\n",
    "        \"target_test_label_loss\": target_test_label_loss,\n",
    "        \"source_val_label_accuracy\": source_val_label_accuracy,\n",
    "        \"source_val_label_loss\": source_val_label_loss,\n",
    "        \"target_val_label_accuracy\": target_val_label_accuracy,\n",
    "        \"target_val_label_loss\": target_val_label_loss,\n",
    "        \"total_epochs_trained\": total_epochs_trained,\n",
    "        \"total_experiment_time_secs\": total_experiment_time_secs,\n",
    "        \"confusion\": confusion,\n",
    "        \"per_domain_accuracy\": per_domain_accuracy,\n",
    "    },\n",
    "    \"history\": history,\n",
    "    \"dataset_metrics\": get_dataset_metrics(ds, \"cnn\"),\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
