{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9fea5f46",
   "metadata": {},
   "source": [
    "# ORACLE PTN Template\n",
    "This notebook serves as a template for ORACLE PTN experiments  \n",
    "It can be run on its own by setting STANDALONE to True (do a find for \"STANDALONE\" to see where)  \n",
    "But it is intended to be executed as part of a *papermill.py script. See any of the   \n",
    "experimentes with a papermill script to get started with that workflow.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0902182a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "    \n",
    "import os, json, sys, time, random\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "from  easydict import EasyDict\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from steves_models.steves_ptn import Steves_Prototypical_Network\n",
    "\n",
    "from steves_utils.lazy_iterable_wrapper import Lazy_Iterable_Wrapper\n",
    "from steves_utils.iterable_aggregator import Iterable_Aggregator\n",
    "from steves_utils.ptn_train_eval_test_jig import  PTN_Train_Eval_Test_Jig\n",
    "from steves_utils.torch_sequential_builder import build_sequential\n",
    "from steves_utils.torch_utils import get_dataset_metrics, ptn_confusion_by_domain_over_dataloader\n",
    "from steves_utils.utils_v2 import (per_domain_accuracy_from_confusion, get_datasets_base_path)\n",
    "from steves_utils.PTN.utils import independent_accuracy_assesment\n",
    "\n",
    "from steves_utils.simple_datasets.ORACLE.episodic_dataset_accessor import get_episodic_dataloaders\n",
    "from steves_utils.ORACLE.utils_v2 import (\n",
    "    ALL_DISTANCES_FEET,\n",
    "    ALL_SERIAL_NUMBERS,\n",
    "    ALL_RUNS,\n",
    "    serial_number_to_id\n",
    ")\n",
    "\n",
    "from steves_utils.ptn_do_report import (\n",
    "    get_jig_diagram,\n",
    "    get_results_table,\n",
    "    get_parameters_table,\n",
    "    get_domain_accuracies,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c840b4",
   "metadata": {},
   "source": [
    "# Allowed Parameters\n",
    "These are allowed parameters, not defaults\n",
    "Each of these values need to be present in the injected parameters (the notebook will raise an exception if they are not present)\n",
    "\n",
    "Papermill uses the cell tag \"parameters\" to inject the real parameters below this cell.\n",
    "Enable tags to see what I mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3f0049",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "allowed_parameters = {}\n",
    "allowed_parameters[\"experiment_name\"] = \"MANUAL ORACLE PTN\"\n",
    "allowed_parameters[\"lr\"] = 0.001\n",
    "allowed_parameters[\"device\"] = \"cuda\"\n",
    "\n",
    "allowed_parameters[\"seed\"] = 1337\n",
    "allowed_parameters[\"desired_classes_source\"] = ALL_SERIAL_NUMBERS\n",
    "allowed_parameters[\"desired_classes_target\"] = ALL_SERIAL_NUMBERS\n",
    "\n",
    "allowed_parameters[\"source_domains\"] = [38,]\n",
    "allowed_parameters[\"target_domains\"] = [20,44,\n",
    "    2,\n",
    "    8,\n",
    "    14,\n",
    "    26,\n",
    "    32,\n",
    "    50,\n",
    "    56,\n",
    "    62\n",
    "]\n",
    "\n",
    "allowed_parameters[\"num_examples_per_class_per_domain_source\"]=100\n",
    "allowed_parameters[\"num_examples_per_class_per_domain_target\"]=100\n",
    "\n",
    "allowed_parameters[\"n_shot\"] = 3\n",
    "allowed_parameters[\"n_way\"]  = len(allowed_parameters[\"desired_classes_source\"])\n",
    "allowed_parameters[\"n_query\"]  = 2\n",
    "allowed_parameters[\"train_k_factor\"] = 1\n",
    "allowed_parameters[\"val_k_factor\"] = 2\n",
    "allowed_parameters[\"test_k_factor\"] = 2\n",
    "\n",
    "\n",
    "allowed_parameters[\"n_epoch\"] = 3\n",
    "\n",
    "allowed_parameters[\"patience\"] = 10\n",
    "allowed_parameters[\"criteria_for_best\"] = \"target\"\n",
    "allowed_parameters[\"normalize_source\"] = False\n",
    "allowed_parameters[\"normalize_target\"] = False\n",
    "\n",
    "\n",
    "allowed_parameters[\"x_net\"] =     [\n",
    "    {\"class\": \"nnReshape\", \"kargs\": {\"shape\":[-1, 1, 2, 256]}},\n",
    "    {\"class\": \"Conv2d\", \"kargs\": { \"in_channels\":1, \"out_channels\":256, \"kernel_size\":(1,7), \"bias\":False, \"padding\":(0,3), },},\n",
    "    {\"class\": \"ReLU\", \"kargs\": {\"inplace\": True}},\n",
    "    {\"class\": \"BatchNorm2d\", \"kargs\": {\"num_features\":256}},\n",
    "\n",
    "    {\"class\": \"Conv2d\", \"kargs\": { \"in_channels\":256, \"out_channels\":80, \"kernel_size\":(2,7), \"bias\":True, \"padding\":(0,3), },},\n",
    "    {\"class\": \"ReLU\", \"kargs\": {\"inplace\": True}},\n",
    "    {\"class\": \"BatchNorm2d\", \"kargs\": {\"num_features\":80}},\n",
    "    {\"class\": \"Flatten\", \"kargs\": {}},\n",
    "\n",
    "    {\"class\": \"Linear\", \"kargs\": {\"in_features\": 80*256, \"out_features\": 256}}, # 80 units per IQ pair\n",
    "    {\"class\": \"ReLU\", \"kargs\": {\"inplace\": True}},\n",
    "    {\"class\": \"BatchNorm1d\", \"kargs\": {\"num_features\":256}},\n",
    "\n",
    "    {\"class\": \"Linear\", \"kargs\": {\"in_features\": 256, \"out_features\": 256}},\n",
    "]\n",
    "\n",
    "# Parameters relevant to results\n",
    "# These parameters will basically never need to change\n",
    "allowed_parameters[\"NUM_LOGS_PER_EPOCH\"] = 10\n",
    "allowed_parameters[\"BEST_MODEL_PATH\"] = \"./best_model.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa1cc33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set this to True if you want to run this template directly\n",
    "STANDALONE = False\n",
    "if STANDALONE:\n",
    "    if not 'parameters' in locals() and not 'parameters' in globals():\n",
    "        print(\"parameters not injected, running with allowed_parameters!\")\n",
    "        parameters = allowed_parameters\n",
    "\n",
    "if not 'parameters' in locals() and not 'parameters' in globals():\n",
    "    raise Exception(\"Parameter injection failed\")\n",
    "\n",
    "#Use an easy dict for all the parameters\n",
    "p = EasyDict(parameters)\n",
    "\n",
    "allowed_keys =set(allowed_parameters.keys())\n",
    "supplied_keys = set(p.keys())\n",
    "\n",
    "\n",
    "\n",
    "if  supplied_keys != allowed_keys:\n",
    "    print(\"Parameters are incorrect\")\n",
    "    if len(supplied_keys - allowed_keys)>0: print(\"Shouldn't have:\", str(supplied_keys - allowed_keys))\n",
    "    if len(allowed_keys - supplied_keys)>0: print(\"Need to have:\", str(allowed_keys - supplied_keys))\n",
    "    raise RuntimeError(\"Parameters are incorrect\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a028d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################\n",
    "# Set the RNGs and make it all deterministic\n",
    "###################################\n",
    "np.random.seed(p.seed)\n",
    "random.seed(p.seed)\n",
    "torch.manual_seed(p.seed)\n",
    "\n",
    "torch.use_deterministic_algorithms(True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b691acf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# Required since we're pulling in 3rd party code\n",
    "torch.set_default_dtype(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fba671",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################\n",
    "# Build the network(s)\n",
    "# Note: It's critical to do this AFTER setting the RNG\n",
    "###################################\n",
    "x_net = build_sequential(p.x_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7e61cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time_secs = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5442bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################\n",
    "# Build the dataset\n",
    "###################################\n",
    "source_original_train, source_original_val, source_original_test = get_episodic_dataloaders(\n",
    "    serial_numbers=p.desired_classes_source,\n",
    "    distances=p.source_domains,\n",
    "    num_examples_per_distance_per_serial=p.num_examples_per_class_per_domain_source,\n",
    "    iterator_seed=p.seed,\n",
    "    n_shot=p.n_shot,\n",
    "    n_way=p.n_way,\n",
    "    n_query=p.n_query,\n",
    "    train_val_test_k_factors=(p.train_k_factor,p.val_k_factor,p.test_k_factor),\n",
    "    normalize_type=p.normalize_source,\n",
    "#         pickle_path=os.path.join(get_datasets_base_path(), \"oracle.frame_indexed.stratified_ds.2022A.pkl\"),\n",
    ")\n",
    "\n",
    "target_original_train, target_original_val, target_original_test = get_episodic_dataloaders(\n",
    "    serial_numbers=p.desired_classes_target,\n",
    "    distances=p.target_domains,\n",
    "    num_examples_per_distance_per_serial=p.num_examples_per_class_per_domain_target,\n",
    "    iterator_seed=p.seed,\n",
    "    n_shot=p.n_shot,\n",
    "    n_way=p.n_way,\n",
    "    n_query=p.n_query,\n",
    "    train_val_test_k_factors=(p.train_k_factor,p.val_k_factor,p.test_k_factor),\n",
    "    normalize_type=p.normalize_target,\n",
    "#         pickle_path=os.path.join(get_datasets_base_path(), \"oracle.frame_indexed.stratified_ds.2022A.pkl\"),\n",
    ")\n",
    "\n",
    "\n",
    "# For CNN We only use X and Y. And we only train on the source.\n",
    "# Properly form the data using a transform lambda and Lazy_Iterable_Wrapper. Finally wrap them in a dataloader\n",
    "\n",
    "transform_lambda = lambda ex: ex[1] # Original is (<domain>, <episode>) so we strip down to episode only\n",
    "\n",
    "source_processed_train = Lazy_Iterable_Wrapper(source_original_train, transform_lambda)\n",
    "source_processed_val   = Lazy_Iterable_Wrapper(source_original_val, transform_lambda)\n",
    "source_processed_test  = Lazy_Iterable_Wrapper(source_original_test, transform_lambda)\n",
    "\n",
    "target_processed_train = Lazy_Iterable_Wrapper(target_original_train, transform_lambda)\n",
    "target_processed_val   = Lazy_Iterable_Wrapper(target_original_val, transform_lambda)\n",
    "target_processed_test  = Lazy_Iterable_Wrapper(target_original_test, transform_lambda)\n",
    "\n",
    "datasets = EasyDict({\n",
    "    \"source\": {\n",
    "        \"original\": {\"train\":source_original_train, \"val\":source_original_val, \"test\":source_original_test},\n",
    "        \"processed\": {\"train\":source_processed_train, \"val\":source_processed_val, \"test\":source_processed_test}\n",
    "    },\n",
    "    \"target\": {\n",
    "        \"original\": {\"train\":target_original_train, \"val\":target_original_val, \"test\":target_original_test},\n",
    "        \"processed\": {\"train\":target_processed_train, \"val\":target_processed_val, \"test\":target_processed_test}\n",
    "    },\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbdacba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################\n",
    "# Build the model\n",
    "###################################\n",
    "model = Steves_Prototypical_Network(x_net, x_shape=(2,256))\n",
    "optimizer = Adam(params=model.parameters(), lr=p.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b39ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################\n",
    "# train\n",
    "###################################\n",
    "jig = PTN_Train_Eval_Test_Jig(model, p.BEST_MODEL_PATH, p.device)\n",
    "\n",
    "jig.train(\n",
    "    train_iterable=datasets.source.processed.train,\n",
    "    source_val_iterable=datasets.source.processed.val,\n",
    "    target_val_iterable=datasets.target.processed.val,\n",
    "    num_epochs=p.n_epoch,\n",
    "    num_logs_per_epoch=p.NUM_LOGS_PER_EPOCH,\n",
    "    patience=p.patience,\n",
    "    optimizer=optimizer,\n",
    "    criteria_for_best=p.criteria_for_best,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e8fabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_experiment_time_secs = time.time() - start_time_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b9595b",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################\n",
    "# Evaluate the model\n",
    "###################################\n",
    "source_test_label_accuracy, source_test_label_loss = jig.test(datasets.source.processed.test)\n",
    "target_test_label_accuracy, target_test_label_loss = jig.test(datasets.target.processed.test)\n",
    "\n",
    "source_val_label_accuracy, source_val_label_loss = jig.test(datasets.source.processed.val)\n",
    "target_val_label_accuracy, target_val_label_loss = jig.test(datasets.target.processed.val)\n",
    "\n",
    "history = jig.get_history()\n",
    "\n",
    "total_epochs_trained = len(history[\"epoch_indices\"])\n",
    "\n",
    "val_dl = Iterable_Aggregator((datasets.source.original.val,datasets.target.original.val))\n",
    "\n",
    "confusion = ptn_confusion_by_domain_over_dataloader(model, p.device, val_dl)\n",
    "per_domain_accuracy = per_domain_accuracy_from_confusion(confusion)\n",
    "\n",
    "# Add a key to per_domain_accuracy for if it was a source domain\n",
    "for domain, accuracy in per_domain_accuracy.items():\n",
    "    per_domain_accuracy[domain] = {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"source?\": domain in p.source_domains\n",
    "    }\n",
    "\n",
    "# Do an independent accuracy assesment JUST TO BE SURE!\n",
    "_source_test_label_accuracy = independent_accuracy_assesment(model, datasets.source.processed.test)\n",
    "_target_test_label_accuracy = independent_accuracy_assesment(model, datasets.target.processed.test)\n",
    "_source_val_label_accuracy = independent_accuracy_assesment(model, datasets.source.processed.val)\n",
    "_target_val_label_accuracy = independent_accuracy_assesment(model, datasets.target.processed.val)\n",
    "\n",
    "assert(_source_test_label_accuracy == source_test_label_accuracy)\n",
    "assert(_target_test_label_accuracy == target_test_label_accuracy)\n",
    "assert(_source_val_label_accuracy == source_val_label_accuracy)\n",
    "assert(_target_val_label_accuracy == target_val_label_accuracy)\n",
    "\n",
    "experiment = {\n",
    "    \"experiment_name\": p.experiment_name,\n",
    "    \"parameters\": dict(p),\n",
    "    \"results\": {\n",
    "        \"source_test_label_accuracy\": source_test_label_accuracy,\n",
    "        \"source_test_label_loss\": source_test_label_loss,\n",
    "        \"target_test_label_accuracy\": target_test_label_accuracy,\n",
    "        \"target_test_label_loss\": target_test_label_loss,\n",
    "        \"source_val_label_accuracy\": source_val_label_accuracy,\n",
    "        \"source_val_label_loss\": source_val_label_loss,\n",
    "        \"target_val_label_accuracy\": target_val_label_accuracy,\n",
    "        \"target_val_label_loss\": target_val_label_loss,\n",
    "        \"total_epochs_trained\": total_epochs_trained,\n",
    "        \"total_experiment_time_secs\": total_experiment_time_secs,\n",
    "        \"confusion\": confusion,\n",
    "        \"per_domain_accuracy\": per_domain_accuracy,\n",
    "    },\n",
    "    \"history\": history,\n",
    "    \"dataset_metrics\": get_dataset_metrics(datasets, \"ptn\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3528c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################\n",
    "# Write out the results\n",
    "###################################\n",
    "def write_results(p:EasyDict, experiment)->None:\n",
    "    with open(p.EXPERIMENT_JSON_PATH, \"w\") as f:\n",
    "        json.dump(experiment, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a21829",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = get_jig_diagram(experiment)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8a0f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_results_table(experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6e89c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_parameters_table(experiment)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8dc689",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_domain_accuracies(experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74ae082",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Source Test Label Accuracy:\", experiment[\"results\"][\"source_test_label_accuracy\"], \"Target Test Label Accuracy:\", experiment[\"results\"][\"target_test_label_accuracy\"])\n",
    "print(\"Source Val Label Accuracy:\", experiment[\"results\"][\"source_val_label_accuracy\"], \"Target Val Label Accuracy:\", experiment[\"results\"][\"target_val_label_accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dacca602",
   "metadata": {
    "tags": [
     "experiment_json"
    ]
   },
   "outputs": [],
   "source": [
    "json.dumps(experiment)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
