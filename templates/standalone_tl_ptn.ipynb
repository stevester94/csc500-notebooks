{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9fea5f46",
   "metadata": {},
   "source": [
    "# Transfer Learning Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0902182a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "    \n",
    "import os, json, sys, time, random\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "from  easydict import EasyDict\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from steves_models.steves_ptn import Steves_Prototypical_Network\n",
    "\n",
    "from steves_utils.lazy_iterable_wrapper import Lazy_Iterable_Wrapper\n",
    "from steves_utils.iterable_aggregator import Iterable_Aggregator\n",
    "from steves_utils.ptn_train_eval_test_jig import  PTN_Train_Eval_Test_Jig\n",
    "from steves_utils.torch_sequential_builder import build_sequential\n",
    "from steves_utils.torch_utils import get_dataset_metrics, ptn_confusion_by_domain_over_dataloader\n",
    "from steves_utils.utils_v2 import (per_domain_accuracy_from_confusion, get_datasets_base_path)\n",
    "from steves_utils.PTN.utils import independent_accuracy_assesment\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from steves_utils.stratified_dataset.episodic_accessor import Episodic_Accessor_Factory\n",
    "\n",
    "from steves_utils.ptn_do_report import (\n",
    "    get_loss_curve,\n",
    "    get_results_table,\n",
    "    get_parameters_table,\n",
    "    get_domain_accuracies,\n",
    ")\n",
    "\n",
    "from steves_utils.transforms import get_chained_transform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c840b4",
   "metadata": {},
   "source": [
    "# Allowed Parameters\n",
    "These are allowed parameters, not defaults\n",
    "Each of these values need to be present in the injected parameters (the notebook will raise an exception if they are not present)\n",
    "\n",
    "Papermill uses the cell tag \"parameters\" to inject the real parameters below this cell.\n",
    "Enable tags to see what I mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd44eb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "required_parameters = {\n",
    "    \"experiment_name\",\n",
    "    \"lr\",\n",
    "    \"device\",\n",
    "    \"seed\",\n",
    "    \"dataset_seed\",\n",
    "    \"n_shot\",\n",
    "    \"n_query\",\n",
    "    \"n_way\",\n",
    "    \"train_k_factor\",\n",
    "    \"val_k_factor\",\n",
    "    \"test_k_factor\",\n",
    "    \"n_epoch\",\n",
    "    \"patience\",\n",
    "    \"criteria_for_best\",\n",
    "    \"x_net\",\n",
    "    \"datasets\",\n",
    "    \"torch_default_dtype\",\n",
    "    \"NUM_LOGS_PER_EPOCH\",\n",
    "    \"BEST_MODEL_PATH\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa3f0049",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "from steves_utils.CORES.utils import (\n",
    "    ALL_NODES,\n",
    "    ALL_NODES_MINIMUM_1000_EXAMPLES,\n",
    "    ALL_DAYS\n",
    ")\n",
    "\n",
    "from steves_utils.ORACLE.utils_v2 import (\n",
    "    ALL_DISTANCES_FEET_NARROWED,\n",
    "    ALL_RUNS,\n",
    "    ALL_SERIAL_NUMBERS,\n",
    ")\n",
    "\n",
    "import steves_utils.wisig.utils as wisig\n",
    "\n",
    "\n",
    "standalone_parameters = {}\n",
    "standalone_parameters[\"experiment_name\"] = \"STANDALONE PTN\"\n",
    "standalone_parameters[\"lr\"] = 0.00001\n",
    "standalone_parameters[\"device\"] = \"cuda\"\n",
    "\n",
    "standalone_parameters[\"seed\"] = 1337\n",
    "standalone_parameters[\"dataset_seed\"] = 1337\n",
    "\n",
    "standalone_parameters[\"n_way\"] = 8\n",
    "standalone_parameters[\"n_shot\"] = 3\n",
    "standalone_parameters[\"n_query\"]  = 2\n",
    "standalone_parameters[\"train_k_factor\"] = 1\n",
    "standalone_parameters[\"val_k_factor\"] = 2\n",
    "standalone_parameters[\"test_k_factor\"] = 2\n",
    "\n",
    "\n",
    "standalone_parameters[\"n_epoch\"] = 100\n",
    "\n",
    "standalone_parameters[\"patience\"] = 10\n",
    "standalone_parameters[\"criteria_for_best\"] = \"target_accuracy\"\n",
    "\n",
    "standalone_parameters[\"datasets\"] = [\n",
    "    {\n",
    "        \"labels\": list(set(ALL_NODES)-set(ALL_NODES_MINIMUM_1000_EXAMPLES)),\n",
    "        \"domains\": ALL_DAYS,\n",
    "        \"num_examples_per_domain_per_label\": 100,\n",
    "        \"pickle_path\": os.path.join(get_datasets_base_path(), \"cores.stratified_ds.2022A.pkl\"),\n",
    "        \"source_or_target_dataset\": \"source\", # Fill in later\n",
    "        \"x_transforms\": [\"lowpass_+/-10MHz\", \"take_200\"],\n",
    "        \"episode_transforms\": [],\n",
    "        \"domain_prefix\": \"C_A_\"\n",
    "    },\n",
    "#     {\n",
    "#         \"labels\": ALL_NODES_MINIMUM_1000_EXAMPLES,\n",
    "#         \"domains\": ALL_DAYS,\n",
    "#         \"num_examples_per_domain_per_label\": 1000,\n",
    "#         \"pickle_path\": os.path.join(get_datasets_base_path(), \"cores.stratified_ds.2022A.pkl\"),\n",
    "#         \"source_or_target_dataset\": \"source\", # Fill in later\n",
    "#         \"x_transforms\": [\"lowpass_+/-10MHz\", \"take_200\"],\n",
    "#         \"episode_transforms\": [],\n",
    "#         \"domain_prefix\": \"C_B_\"\n",
    "#     },\n",
    "#     {\n",
    "#         \"labels\": list(set(wisig.ALL_NODES_MINIMUM_100_EXAMPLES) - set(wisig.ALL_NODES_MINIMUM_500_EXAMPLES + wisig.ALL_NODES_MINIMUM_1000_EXAMPLES)),\n",
    "#         \"domains\": wisig.ALL_DAYS,\n",
    "#         \"num_examples_per_domain_per_label\": 100,\n",
    "#         \"pickle_path\": os.path.join(get_datasets_base_path(), \"wisig.node3-19.stratified_ds.2022A.pkl\"),\n",
    "#         \"source_or_target_dataset\": \"source\", # Fill in later\n",
    "#         \"x_transforms\": [\"lowpass_+/-10MHz\", \"take_200\"],\n",
    "#         \"episode_transforms\": [],\n",
    "#         \"domain_prefix\": \"W_A_\"\n",
    "#     },\n",
    "#     {\n",
    "#         \"labels\": list(set(wisig.ALL_NODES_MINIMUM_500_EXAMPLES) - set(wisig.ALL_NODES_MINIMUM_1000_EXAMPLES)),\n",
    "#         \"domains\": wisig.ALL_DAYS,\n",
    "#         \"num_examples_per_domain_per_label\": 500,\n",
    "#         \"pickle_path\": os.path.join(get_datasets_base_path(), \"wisig.node3-19.stratified_ds.2022A.pkl\"),\n",
    "#         \"source_or_target_dataset\": \"source\", # Fill in later\n",
    "#         \"x_transforms\": [\"lowpass_+/-10MHz\", \"take_200\"],\n",
    "#         \"episode_transforms\": [],\n",
    "#         \"domain_prefix\": \"W_B_\"\n",
    "#     },\n",
    "#     {\n",
    "#         \"labels\": wisig.ALL_NODES_MINIMUM_1000_EXAMPLES,\n",
    "#         \"domains\": wisig.ALL_DAYS,\n",
    "#         \"num_examples_per_domain_per_label\": 1000,\n",
    "#         \"pickle_path\": os.path.join(get_datasets_base_path(), \"wisig.node3-19.stratified_ds.2022A.pkl\"),\n",
    "#         \"source_or_target_dataset\": \"source\", # Fill in later\n",
    "#         \"x_transforms\": [\"lowpass_+/-10MHz\", \"take_200\"],\n",
    "#         \"episode_transforms\": [],\n",
    "#         \"domain_prefix\": \"W_C_\"\n",
    "#     },\n",
    "#     {\n",
    "#         \"labels\": ALL_SERIAL_NUMBERS,\n",
    "#         \"domains\": ALL_DISTANCES_FEET_NARROWED[:1],\n",
    "#         \"num_examples_per_domain_per_label\": 500,\n",
    "#         \"pickle_path\": os.path.join(get_datasets_base_path(), \"oracle.Run2_framed_2000Examples_stratified_ds.2022A.pkl\"),\n",
    "#         \"source_or_target_dataset\": \"source\", # Fill in later\n",
    "#         \"x_transforms\": [\"jitter_256_10\", \"take_200\", \"resample_20Msps_to_25Msps\"],\n",
    "#         \"episode_transforms\": [],\n",
    "#         \"domain_prefix\": \"O_2_\"\n",
    "#     },\n",
    "    {\n",
    "        \"labels\": ALL_SERIAL_NUMBERS,\n",
    "        \"domains\": ALL_DISTANCES_FEET_NARROWED,\n",
    "        \"num_examples_per_domain_per_label\": 2000,\n",
    "        \"pickle_path\": os.path.join(get_datasets_base_path(), \"oracle.Run1_framed_2000Examples_stratified_ds.2022A.pkl\"),\n",
    "        \"source_or_target_dataset\": \"target\", # Fill in later\n",
    "        \"x_transforms\": [\"take_200\", \"resample_20Msps_to_25Msps\"],\n",
    "        \"episode_transforms\": [],\n",
    "        \"domain_prefix\": \"O_1_\"\n",
    "    }\n",
    "]\n",
    "\n",
    "standalone_parameters[\"torch_default_dtype\"] = \"torch.float32\" \n",
    "\n",
    "\n",
    "\n",
    "standalone_parameters[\"x_net\"] =     [\n",
    "    {\"class\": \"nnReshape\", \"kargs\": {\"shape\":[-1, 1, 2, 200]}},\n",
    "    {\"class\": \"Conv2d\", \"kargs\": { \"in_channels\":1, \"out_channels\":256, \"kernel_size\":[1,7], \"bias\":False, \"padding\":[0,3], },},\n",
    "    {\"class\": \"ReLU\", \"kargs\": {\"inplace\": True}},\n",
    "    {\"class\": \"BatchNorm2d\", \"kargs\": {\"num_features\":256}},\n",
    "\n",
    "    {\"class\": \"Conv2d\", \"kargs\": { \"in_channels\":256, \"out_channels\":80, \"kernel_size\":[2,7], \"bias\":True, \"padding\":[0,3], },},\n",
    "    {\"class\": \"ReLU\", \"kargs\": {\"inplace\": True}},\n",
    "    {\"class\": \"BatchNorm2d\", \"kargs\": {\"num_features\":80}},\n",
    "    {\"class\": \"Flatten\", \"kargs\": {}},\n",
    "\n",
    "    {\"class\": \"Linear\", \"kargs\": {\"in_features\": 80*200, \"out_features\": 256}}, # 80 units per IQ pair\n",
    "    {\"class\": \"ReLU\", \"kargs\": {\"inplace\": True}},\n",
    "    {\"class\": \"BatchNorm1d\", \"kargs\": {\"num_features\":256}},\n",
    "\n",
    "    {\"class\": \"Linear\", \"kargs\": {\"in_features\": 256, \"out_features\": 256}},\n",
    "]\n",
    "\n",
    "# Parameters relevant to results\n",
    "# These parameters will basically never need to change\n",
    "standalone_parameters[\"NUM_LOGS_PER_EPOCH\"] = 10\n",
    "standalone_parameters[\"BEST_MODEL_PATH\"] = \"./best_model.pth\"\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8fa1cc33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters not injected, running with standalone_parameters\n"
     ]
    }
   ],
   "source": [
    "# Set this to True if you want to run this template directly\n",
    "STANDALONE = True\n",
    "if STANDALONE:\n",
    "    print(\"parameters not injected, running with standalone_parameters\")\n",
    "    parameters = standalone_parameters\n",
    "\n",
    "if not 'parameters' in locals() and not 'parameters' in globals():\n",
    "    raise Exception(\"Parameter injection failed\")\n",
    "\n",
    "#Use an easy dict for all the parameters\n",
    "p = EasyDict(parameters)\n",
    "\n",
    "supplied_keys = set(p.keys())\n",
    "\n",
    "if  supplied_keys != required_parameters:\n",
    "    print(\"Parameters are incorrect\")\n",
    "    if len(supplied_keys - required_parameters)>0: print(\"Shouldn't have:\", str(supplied_keys - required_parameters))\n",
    "    if len(required_parameters - supplied_keys)>0: print(\"Need to have:\", str(required_parameters - supplied_keys))\n",
    "    raise RuntimeError(\"Parameters are incorrect\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a028d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################\n",
    "# Set the RNGs and make it all deterministic\n",
    "###################################\n",
    "np.random.seed(p.seed)\n",
    "random.seed(p.seed)\n",
    "torch.manual_seed(p.seed)\n",
    "\n",
    "torch.use_deterministic_algorithms(True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b691acf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################\n",
    "# The stratified datasets honor this\n",
    "###########################################\n",
    "torch.set_default_dtype(eval(p.torch_default_dtype))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5fba671",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################\n",
    "# Build the network(s)\n",
    "# Note: It's critical to do this AFTER setting the RNG\n",
    "###################################\n",
    "x_net = build_sequential(p.x_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d7e61cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time_secs = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6b67dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "p.domains_source = []\n",
    "p.domains_target = []\n",
    "\n",
    "\n",
    "train_original_source = []\n",
    "val_original_source   = []\n",
    "test_original_source  = []\n",
    "\n",
    "train_original_target = []\n",
    "val_original_target   = []\n",
    "test_original_target  = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3d9c3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# global_x_transform_func = lambda x: normalize(x.to(torch.get_default_dtype()), \"unit_power\") # unit_power, unit_mag\n",
    "# global_x_transform_func = lambda x: normalize(x, \"unit_power\") # unit_power, unit_mag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "acb78fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_dataset(\n",
    "    labels,\n",
    "    domains,\n",
    "    pickle_path,\n",
    "    x_transforms,\n",
    "    episode_transforms,\n",
    "    domain_prefix,\n",
    "    num_examples_per_domain_per_label,\n",
    "    source_or_target_dataset:str,\n",
    "    iterator_seed=p.seed,\n",
    "    dataset_seed=p.dataset_seed,\n",
    "    n_shot=p.n_shot,\n",
    "    n_way=p.n_way,\n",
    "    n_query=p.n_query,\n",
    "    train_val_test_k_factors=(p.train_k_factor,p.val_k_factor,p.test_k_factor),\n",
    "):\n",
    "   \n",
    "    if x_transforms == []: x_transform = None\n",
    "    else: x_transform = get_chained_transform(x_transforms)\n",
    "    \n",
    "    if episode_transforms == []: episode_transform = None\n",
    "    else: raise Exception(\"episode_transforms not implemented\")\n",
    "    \n",
    "    episode_transform = lambda tup, _prefix=domain_prefix: (_prefix + str(tup[0]), tup[1])\n",
    "\n",
    "\n",
    "    eaf = Episodic_Accessor_Factory(\n",
    "        labels=labels,\n",
    "        domains=domains,\n",
    "        num_examples_per_domain_per_label=num_examples_per_domain_per_label,\n",
    "        iterator_seed=iterator_seed,\n",
    "        dataset_seed=dataset_seed,\n",
    "        n_shot=n_shot,\n",
    "        n_way=n_way,\n",
    "        n_query=n_query,\n",
    "        train_val_test_k_factors=train_val_test_k_factors,\n",
    "        pickle_path=pickle_path,\n",
    "        x_transform_func=x_transform,\n",
    "    )\n",
    "\n",
    "    train, val, test = eaf.get_train(), eaf.get_val(), eaf.get_test()\n",
    "    train = Lazy_Iterable_Wrapper(train, episode_transform)\n",
    "    val = Lazy_Iterable_Wrapper(val, episode_transform)\n",
    "    test = Lazy_Iterable_Wrapper(test, episode_transform)\n",
    "\n",
    "    if source_or_target_dataset==\"source\":\n",
    "        train_original_source.append(train)\n",
    "        val_original_source.append(val)\n",
    "        test_original_source.append(test)\n",
    "\n",
    "        p.domains_source.extend(\n",
    "            [domain_prefix + str(u) for u in domains]\n",
    "        )\n",
    "    elif source_or_target_dataset==\"target\":\n",
    "        train_original_target.append(train)\n",
    "        val_original_target.append(val)\n",
    "        test_original_target.append(test)\n",
    "        p.domains_target.extend(\n",
    "            [domain_prefix + str(u) for u in domains]\n",
    "        )\n",
    "    else:\n",
    "        raise Exception(f\"invalid source_or_target_dataset: {source_or_target_dataset}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe266617",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ds in p.datasets:\n",
    "    add_dataset(**ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd5442bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################\n",
    "# Build the dataset\n",
    "###################################\n",
    "train_original_source = Iterable_Aggregator(train_original_source, p.seed)\n",
    "val_original_source = Iterable_Aggregator(val_original_source, p.seed)\n",
    "test_original_source = Iterable_Aggregator(test_original_source, p.seed)\n",
    "\n",
    "\n",
    "train_original_target = Iterable_Aggregator(train_original_target, p.seed)\n",
    "val_original_target = Iterable_Aggregator(val_original_target, p.seed)\n",
    "test_original_target = Iterable_Aggregator(test_original_target, p.seed)\n",
    "\n",
    "# For CNN We only use X and Y. And we only train on the source.\n",
    "# Properly form the data using a transform lambda and Lazy_Iterable_Wrapper. Finally wrap them in a dataloader\n",
    "\n",
    "transform_lambda = lambda ex: ex[1] # Original is (<domain>, <episode>) so we strip down to episode only\n",
    "\n",
    "train_processed_source = Lazy_Iterable_Wrapper(train_original_source, transform_lambda)\n",
    "val_processed_source   = Lazy_Iterable_Wrapper(val_original_source, transform_lambda)\n",
    "test_processed_source  = Lazy_Iterable_Wrapper(test_original_source, transform_lambda)\n",
    "\n",
    "train_processed_target = Lazy_Iterable_Wrapper(train_original_target, transform_lambda)\n",
    "val_processed_target   = Lazy_Iterable_Wrapper(val_original_target, transform_lambda)\n",
    "test_processed_target  = Lazy_Iterable_Wrapper(test_original_target, transform_lambda)\n",
    "\n",
    "datasets = EasyDict({\n",
    "    \"source\": {\n",
    "        \"original\": {\"train\":train_original_source, \"val\":val_original_source, \"test\":test_original_source},\n",
    "        \"processed\": {\"train\":train_processed_source, \"val\":val_processed_source, \"test\":test_processed_source}\n",
    "    },\n",
    "    \"target\": {\n",
    "        \"original\": {\"train\":train_original_target, \"val\":val_original_target, \"test\":test_original_target},\n",
    "        \"processed\": {\"train\":train_processed_target, \"val\":val_processed_target, \"test\":test_processed_target}\n",
    "    },\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5b3c01fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from steves_utils.transforms import get_average_magnitude, get_average_power\n",
    "\n",
    "# print(set([u for u,_ in val_original_source]))\n",
    "# print(set([u for u,_ in val_original_target]))\n",
    "\n",
    "# s_x, s_y, q_x, q_y, _ = next(iter(train_processed_source))\n",
    "# print(s_x)\n",
    "# print(s_x.shape)\n",
    "\n",
    "# for ds in [\n",
    "#     train_processed_source,\n",
    "#     val_processed_source,\n",
    "#     test_processed_source,\n",
    "#     train_processed_target,\n",
    "#     val_processed_target,\n",
    "#     test_processed_target\n",
    "# ]:\n",
    "#     for s_x, s_y, q_x, q_y, _ in ds:\n",
    "#         for X in (s_x, q_x):\n",
    "#             for x in X:\n",
    "#                 assert np.isclose(get_average_magnitude(x.numpy()), 1.0)\n",
    "#                 assert np.isclose(get_average_power(x.numpy()), 1.0)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bbdacba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 200)\n"
     ]
    }
   ],
   "source": [
    "###################################\n",
    "# Build the model\n",
    "###################################\n",
    "model = Steves_Prototypical_Network(x_net, device=p.device, x_shape=(2,200))\n",
    "optimizer = Adam(params=model.parameters(), lr=p.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "22b39ac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, [batch: 1 / 342], examples_per_second: 365.6019, train_label_loss: 1.5695, \n",
      "epoch: 1, [batch: 35 / 342], examples_per_second: 1437.3302, train_label_loss: 1.1373, \n",
      "epoch: 1, [batch: 69 / 342], examples_per_second: 1346.1178, train_label_loss: 0.8351, \n",
      "epoch: 1, [batch: 103 / 342], examples_per_second: 1437.0771, train_label_loss: 0.7141, \n",
      "epoch: 1, [batch: 137 / 342], examples_per_second: 1374.5464, train_label_loss: 0.5777, \n",
      "epoch: 1, [batch: 171 / 342], examples_per_second: 1439.1702, train_label_loss: 0.5012, \n",
      "epoch: 1, [batch: 205 / 342], examples_per_second: 1445.4948, train_label_loss: 0.5229, \n",
      "epoch: 1, [batch: 239 / 342], examples_per_second: 1546.9313, train_label_loss: 0.7502, \n",
      "epoch: 1, [batch: 273 / 342], examples_per_second: 1475.8168, train_label_loss: 0.4062, \n",
      "epoch: 1, [batch: 307 / 342], examples_per_second: 1398.7815, train_label_loss: 0.3600, \n",
      "=============================================================\n",
      "epoch: 1, source_val_acc_label: 0.9331, target_val_acc_label: 0.5844, source_val_label_loss: 0.4340, target_val_label_loss: 1.9444, \n",
      "=============================================================\n",
      "New best\n",
      "epoch: 2, [batch: 1 / 340], examples_per_second: 3.6705, train_label_loss: 0.3727, \n",
      "epoch: 2, [batch: 34 / 340], examples_per_second: 1399.3077, train_label_loss: 0.4356, \n",
      "epoch: 2, [batch: 68 / 340], examples_per_second: 1448.4087, train_label_loss: 0.8674, \n",
      "epoch: 2, [batch: 102 / 340], examples_per_second: 1432.4194, train_label_loss: 0.1222, \n",
      "epoch: 2, [batch: 136 / 340], examples_per_second: 1430.1869, train_label_loss: 0.2000, \n",
      "epoch: 2, [batch: 170 / 340], examples_per_second: 1502.8120, train_label_loss: 0.1216, \n",
      "epoch: 2, [batch: 204 / 340], examples_per_second: 1450.8131, train_label_loss: 0.1661, \n",
      "epoch: 2, [batch: 238 / 340], examples_per_second: 1489.8821, train_label_loss: 0.1519, \n",
      "epoch: 2, [batch: 272 / 340], examples_per_second: 1464.0691, train_label_loss: 0.3835, \n",
      "epoch: 2, [batch: 306 / 340], examples_per_second: 1475.7168, train_label_loss: 0.1303, \n",
      "=============================================================\n",
      "epoch: 2, source_val_acc_label: 0.9468, target_val_acc_label: 0.6607, source_val_label_loss: 0.1977, target_val_label_loss: 1.6888, \n",
      "=============================================================\n",
      "New best\n",
      "epoch: 3, [batch: 1 / 343], examples_per_second: 3.8769, train_label_loss: 0.0928, \n",
      "epoch: 3, [batch: 35 / 343], examples_per_second: 1412.6331, train_label_loss: 0.1860, \n",
      "epoch: 3, [batch: 69 / 343], examples_per_second: 1378.4353, train_label_loss: 0.0782, \n",
      "epoch: 3, [batch: 103 / 343], examples_per_second: 1466.4622, train_label_loss: 0.0433, \n",
      "epoch: 3, [batch: 137 / 343], examples_per_second: 1396.1276, train_label_loss: 0.0252, \n",
      "epoch: 3, [batch: 172 / 343], examples_per_second: 1447.4244, train_label_loss: 0.0245, \n",
      "epoch: 3, [batch: 206 / 343], examples_per_second: 1445.7047, train_label_loss: 0.4492, \n",
      "epoch: 3, [batch: 240 / 343], examples_per_second: 1417.5686, train_label_loss: 0.0426, \n",
      "epoch: 3, [batch: 274 / 343], examples_per_second: 1430.7236, train_label_loss: 0.2741, \n",
      "epoch: 3, [batch: 308 / 343], examples_per_second: 1435.5932, train_label_loss: 0.2915, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-16:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/mnt/wd500GB/CSC500/csc500-main/venv/lib/python3.8/site-packages/torch/utils/data/_utils/pin_memory.py\", line 28, in _pin_memory_loop\n",
      "    r = in_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 116, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/mnt/wd500GB/CSC500/csc500-main/venv/lib/python3.8/site-packages/torch/multiprocessing/reductions.py\", line 289, in rebuild_storage_fd\n",
      "    fd = df.detach()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/resource_sharer.py\", line 57, in detach\n",
      "    with _resource_sharer.get_connection(self._id) as conn:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/resource_sharer.py\", line 87, in get_connection\n",
      "    c = Client(address, authkey=process.current_process().authkey)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 509, in Client\n",
      "    deliver_challenge(c, authkey)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 740, in deliver_challenge\n",
      "    response = connection.recv_bytes(256)        # reject large message\n",
      "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 414, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_33545/2813601670.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mjig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPTN_Train_Eval_Test_Jig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBEST_MODEL_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m jig.train(\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mtrain_iterable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocessed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0msource_val_iterable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocessed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/wd500GB/CSC500/csc500-main/csc500-utils/steves_utils/ptn_train_eval_test_jig.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, train_iterable, source_val_iterable, target_val_iterable, num_epochs, num_logs_per_epoch, patience, optimizer, criteria_for_best)\u001b[0m\n\u001b[1;32m    107\u001b[0m                     \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m             \u001b[0msource_val_acc_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource_val_label_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_val_iterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m             \u001b[0mtarget_val_acc_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_val_label_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_val_iterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/wd500GB/CSC500/csc500-main/csc500-utils/steves_utils/ptn_train_eval_test_jig.py\u001b[0m in \u001b[0;36mtest\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/wd500GB/CSC500/csc500-main/csc500-models/steves_models/steves_ptn.py\u001b[0m in \u001b[0;36mvalidate\u001b[0;34m(self, val_loader)\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0maverage\u001b[0m \u001b[0mclassification\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0mon\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mvalidation\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \"\"\"\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0mvalidation_accuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_avg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m         \u001b[0;31m# print(f\"Val Accuracy: {(100 * validation_accuracy):.2f}%, Val Avg Loss: {validation_avg_loss:.2f}\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;31m# # If this was the best validation performance, we save the model state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/wd500GB/CSC500/csc500-main/csc500-models/steves_models/steves_ptn.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, data_loader)\u001b[0m\n\u001b[1;32m    126\u001b[0m                 \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m             ) in enumerate(data_loader):\n\u001b[0;32m--> 128\u001b[0;31m                 correct, total, loss = self.evaluate_on_one_task(\n\u001b[0m\u001b[1;32m    129\u001b[0m                     \u001b[0msupport_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msupport_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m                 )\n",
      "\u001b[0;32m/mnt/wd500GB/CSC500/csc500-main/csc500-models/steves_models/steves_ptn.py\u001b[0m in \u001b[0;36mevaluate_on_one_task\u001b[0;34m(self, support_images, support_labels, query_images, query_labels)\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \"\"\"\n\u001b[0;32m--> 150\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_support_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msupport_images\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msupport_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mclassification_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_images\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/wd500GB/CSC500/csc500-main/csc500-utils/easyfsl/methods/prototypical_networks.py\u001b[0m in \u001b[0;36mprocess_support_set\u001b[0;34m(self, support_images, support_labels)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0msupport_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackbone\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msupport_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprototypes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_prototypes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msupport_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msupport_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     def forward(\n",
      "\u001b[0;32m/mnt/wd500GB/CSC500/csc500-main/csc500-utils/easyfsl/utils.py\u001b[0m in \u001b[0;36mcompute_prototypes\u001b[0;34m(support_features, support_labels)\u001b[0m\n\u001b[1;32m     78\u001b[0m     \"\"\"\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m     \u001b[0mn_way\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msupport_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m     \u001b[0;31m# Prototype i is the mean of all instances of features corresponding to labels == i\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     return torch.cat(\n",
      "\u001b[0;32m/mnt/wd500GB/CSC500/csc500-main/venv/lib/python3.8/site-packages/torch/_jit_internal.py\u001b[0m in \u001b[0;36mfn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    420\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mif_true\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mif_false\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mif_true\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mif_false\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/wd500GB/CSC500/csc500-main/venv/lib/python3.8/site-packages/torch/_jit_internal.py\u001b[0m in \u001b[0;36mfn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    420\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mif_true\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mif_false\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mif_true\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mif_false\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/wd500GB/CSC500/csc500-main/venv/lib/python3.8/site-packages/torch/functional.py\u001b[0m in \u001b[0;36m_return_output\u001b[0;34m(input, sorted, return_inverse, return_counts, dim)\u001b[0m\n\u001b[1;32m    819\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_unique_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_inverse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_counts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 821\u001b[0;31m     \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_unique_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_inverse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_counts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    822\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/wd500GB/CSC500/csc500-main/venv/lib/python3.8/site-packages/torch/functional.py\u001b[0m in \u001b[0;36m_unique_impl\u001b[0;34m(input, sorted, return_inverse, return_counts, dim)\u001b[0m\n\u001b[1;32m    733\u001b[0m         )\n\u001b[1;32m    734\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 735\u001b[0;31m         output, inverse_indices, counts = torch._unique2(\n\u001b[0m\u001b[1;32m    736\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    737\u001b[0m             \u001b[0msorted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msorted\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "###################################\n",
    "# train\n",
    "###################################\n",
    "jig = PTN_Train_Eval_Test_Jig(model, p.BEST_MODEL_PATH, p.device)\n",
    "\n",
    "jig.train(\n",
    "    train_iterable=datasets.source.processed.train,\n",
    "    source_val_iterable=datasets.source.processed.val,\n",
    "    target_val_iterable=datasets.target.processed.val,\n",
    "    num_epochs=p.n_epoch,\n",
    "    num_logs_per_epoch=p.NUM_LOGS_PER_EPOCH,\n",
    "    patience=p.patience,\n",
    "    optimizer=optimizer,\n",
    "    criteria_for_best=p.criteria_for_best,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e8fabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_experiment_time_secs = time.time() - start_time_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b9595b",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################\n",
    "# Evaluate the model\n",
    "###################################\n",
    "source_test_label_accuracy, source_test_label_loss = jig.test(datasets.source.processed.test)\n",
    "target_test_label_accuracy, target_test_label_loss = jig.test(datasets.target.processed.test)\n",
    "\n",
    "source_val_label_accuracy, source_val_label_loss = jig.test(datasets.source.processed.val)\n",
    "target_val_label_accuracy, target_val_label_loss = jig.test(datasets.target.processed.val)\n",
    "\n",
    "history = jig.get_history()\n",
    "\n",
    "total_epochs_trained = len(history[\"epoch_indices\"])\n",
    "\n",
    "val_dl = Iterable_Aggregator((datasets.source.original.val,datasets.target.original.val))\n",
    "\n",
    "confusion = ptn_confusion_by_domain_over_dataloader(model, p.device, val_dl)\n",
    "per_domain_accuracy = per_domain_accuracy_from_confusion(confusion)\n",
    "\n",
    "# Add a key to per_domain_accuracy for if it was a source domain\n",
    "for domain, accuracy in per_domain_accuracy.items():\n",
    "    per_domain_accuracy[domain] = {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"source?\": domain in p.domains_source\n",
    "    }\n",
    "\n",
    "# Do an independent accuracy assesment JUST TO BE SURE!\n",
    "# _source_test_label_accuracy = independent_accuracy_assesment(model, datasets.source.processed.test, p.device)\n",
    "# _target_test_label_accuracy = independent_accuracy_assesment(model, datasets.target.processed.test, p.device)\n",
    "# _source_val_label_accuracy = independent_accuracy_assesment(model, datasets.source.processed.val, p.device)\n",
    "# _target_val_label_accuracy = independent_accuracy_assesment(model, datasets.target.processed.val, p.device)\n",
    "\n",
    "# assert(_source_test_label_accuracy == source_test_label_accuracy)\n",
    "# assert(_target_test_label_accuracy == target_test_label_accuracy)\n",
    "# assert(_source_val_label_accuracy == source_val_label_accuracy)\n",
    "# assert(_target_val_label_accuracy == target_val_label_accuracy)\n",
    "\n",
    "experiment = {\n",
    "    \"experiment_name\": p.experiment_name,\n",
    "    \"parameters\": dict(p),\n",
    "    \"results\": {\n",
    "        \"source_test_label_accuracy\": source_test_label_accuracy,\n",
    "        \"source_test_label_loss\": source_test_label_loss,\n",
    "        \"target_test_label_accuracy\": target_test_label_accuracy,\n",
    "        \"target_test_label_loss\": target_test_label_loss,\n",
    "        \"source_val_label_accuracy\": source_val_label_accuracy,\n",
    "        \"source_val_label_loss\": source_val_label_loss,\n",
    "        \"target_val_label_accuracy\": target_val_label_accuracy,\n",
    "        \"target_val_label_loss\": target_val_label_loss,\n",
    "        \"total_epochs_trained\": total_epochs_trained,\n",
    "        \"total_experiment_time_secs\": total_experiment_time_secs,\n",
    "        \"confusion\": confusion,\n",
    "        \"per_domain_accuracy\": per_domain_accuracy,\n",
    "    },\n",
    "    \"history\": history,\n",
    "    \"dataset_metrics\": get_dataset_metrics(datasets, \"ptn\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a21829",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = get_loss_curve(experiment)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8a0f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_results_table(experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8dc689",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_domain_accuracies(experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74ae082",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Source Test Label Accuracy:\", experiment[\"results\"][\"source_test_label_accuracy\"], \"Target Test Label Accuracy:\", experiment[\"results\"][\"target_test_label_accuracy\"])\n",
    "print(\"Source Val Label Accuracy:\", experiment[\"results\"][\"source_val_label_accuracy\"], \"Target Val Label Accuracy:\", experiment[\"results\"][\"target_val_label_accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dacca602",
   "metadata": {
    "tags": [
     "experiment_json"
    ]
   },
   "outputs": [],
   "source": [
    "json.dumps(experiment)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
